# Large Language Models Enable Textual Interpretation of Image-Based Astronomical Transient Classifications - Code Repository

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0) 
TODO: Replace the link below with the actual paper link once puplished
[![DOI](https://img.shields.io/badge/DOI-10.21203/rs.3.rs--5723428/v1-blue)](https://doi.org/10.21203/rs.3.rs-5723428/v1)

This repository contains the code and notebooks associated with the research paper:

TODO: Replace the link below with the actual paper link once puplished
**Paper:** [Large Language Models Enable Textual Interpretation of Image-Based Astronomical Transient Classifications](https://doi.org/10.21203/rs.3.rs-5723428/v1) (Research Square Preprint)

**Authors:** Fiorenzo Stoppa¹, Turan Bulmus², Steven Bloemen³, Stephen J. Smartt¹⁶, Paul J. Groot³⁴⁵, Paul Vreeswijk³, Ken W. Smith¹⁶
(*Affiliations omitted for brevity, see paper*)

## Overview

Modern astronomical surveys generate vast amounts of transient candidate detections. Distinguishing genuine astrophysical signals (e.g., supernovae, variable stars) from imaging artifacts ("bogus" sources) is a critical challenge. While Convolutional Neural Networks (CNNs) have shown success, their "black box" nature limits interpretability.

This work demonstrates the application of Large Language Models (LLMs), specifically Google's Gemini 1.5 Pro (`gemini-1.5-pro-002`), to classify astronomical transients using triplet images (New, Reference, Difference). Using few-shot learning (15 examples per dataset) and carefully engineered prompts, the LLM achieves high accuracy (average 93%, improved to ~96.7% via iteration on MeerLICHT) comparable to CNNs, while simultaneously providing human-readable textual explanations for its classifications. This enhances transparency and aligns with scientific reasoning.

We also showcase a novel approach where an LLM evaluates the coherence and consistency of classifications generated by another LLM instance, enabling targeted refinement and identification of problematic cases.

The code primarily demonstrates the workflow using the MeerLICHT dataset, but the paper discusses applications to Pan-STARRS and ATLAS as well.

## Key Features

*   Few-shot classification of astronomical transients (Real/Bogus) using Gemini 1.5 Pro.
*   Generation of detailed, human-readable textual explanations for each classification.
*   Assignment of an "interest score" (No/Low/High) based on classification and features.
*   Prompt engineering techniques tailored for multimodal LLMs in astronomical image analysis.
*   Batch processing pipeline leveraging Google Cloud Vertex AI Batch Prediction and BigQuery.
*   Evaluation of classification performance (Accuracy, Precision, Recall, Confusion Matrix).
*   Demonstration of LLM-based evaluation ("LLM judging LLM") for coherence assessment.

## Repository Structure
``` bash
spacehack/ 
  ├── data/ # Placeholder for data files (created/downloaded by scripts) 
  │ │ └── pics/ # Generated image files for prompts/analysis
  │ │ └── prompt_pics/ # Images used in few-shot examples 
  │ ├── new_data.npy # Downloaded image triplets 
  │ ├── new_labels.csv # Downloaded labels 
  │ ├── predictions_results.csv # Prediction results from 01_...ipynb
  │ ├── predictions_with_Coherence.csv # Example output from 02_...ipynb
  ├── prompts/ # Placeholder for saved prompt text files (created by scripts) 
  ├── 01_LLM_Classification_Transients.ipynb # Notebook for initial  classification & explanation generation 
  ├── 02_LLM_Judging_LLM_Classifications.ipynb # Notebook for LLM evaluation of the first notebook's outputs 
  ├── CONTRIBUTING.md # Instructions for contributing to the repository 
  ├── helper_functions.py # Utility functions for data handling, prompts, GCP interaction, etc. 
  ├── LICENSE # Software license 
  ├── requirements.txt # Python package dependencies 
  └── README.md # This file
```
  TODO: Add Round2_MeerLICHT.ipynb above


## Setup

1.  **Prerequisites:**
    *   Python 3.10+ (tested with 3.12.3)
    *   Google Cloud Platform (GCP) Project
    *   Enabled GCP APIs:
        *   Vertex AI API (`aiplatform.googleapis.com`)
        *   BigQuery API (`bigquery.googleapis.com`)
    *   GCP Authentication configured for your environment (e.g., run `gcloud auth application-default login` locally, or use Colab's built-in authentication).
    *   A BigQuery Dataset created within your GCP project (the default name `spacehack` is used in the notebooks, update if necessary).

2.  **Clone Repository:**
    ```bash
    git clone https://github.com/turanbulmus/spacehack.git # Or your repo URL
    cd spacehack
    ```

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Note: If running in Colab, package installation might be handled differently, potentially requiring a kernel restart after installation as shown in the notebook comments).*

## Usage

1.  **Configure GCP Variables:**
    *   Open the notebooks (`.ipynb` files).
    *   In the initial cells, update the `PROJECT_ID`, `LOCATION`, and `DATASET_ID` variables to match your specific GCP environment setup.

2.  **Run Notebooks:**
    *   Execute the cells sequentially within a Jupyter or Google Colab environment.
    *   **`01_LLM_Classification_Transients.ipynb`**:
        *   Downloads the MeerLICHT dataset (`.npy` images, `.csv` labels) using `gdown` if not found locally in the `data/` directory.
        *   Prepares image files (`.png`) for the LLM.
        *   Constructs the prompt with few-shot examples.
        *   Sets up and runs a Vertex AI Batch Prediction job to classify all transients.
        *   Retrieves results from BigQuery.
        *   Evaluates performance and generates a confusion matrix.
        *   Saves results to `data/predictions_results.csv`.
    *   **`02_LLM_Judging_LLM_Classifications.ipynb`**:
        *   Requires the output `data/predictions_results.csv` from the first notebook.
        *   Uses an LLM ("judge") to evaluate the coherence score and interest score validity for each classification made by the first LLM.
        *   Runs a second Vertex AI Batch Prediction job for the evaluation task.
        *   Retrieves evaluation results from BigQuery.
        *   Saves evaluated results to `data/predictions_with_Coherence.csv`.
    
    TODO: Add what Round2_MeerLICHT.ipynb does    

3.  **Important Notes:**
    *   Running these notebooks executes jobs on Google Cloud Platform (Vertex AI, BigQuery) which will incur costs.
    *   API usage is subject to GCP quotas. Large batch jobs may take significant time to complete.
    *   The notebooks rely on specific data file IDs from Google Drive for download via `gdown`. If these links become invalid, the data needs to be obtained and placed in the `data/` directory manually.

## Citation

If you use this code or methodology in your research, please cite the original paper:

TODO: Update the actual paper link once published

```bibtex
@article{Stoppa2025LLMTransient,
  title={Large Language Models Enable Textual Interpretation of Image-Based Astronomical Transient Classifications},
  author={Stoppa, Fiorenzo and Bulmus, Turan and Bloemen, Steven and Smartt, Stephen J. and Groot, Paul J. and Vreeswijk, Paul and Smith, Ken W.},
  year={2025},
  journal={Research Square},
  doi={10.21203/rs.3.rs-5723428/v1},
  url={https://doi.org/10.21203/rs.3.rs-5723428/v1},
  note={Preprint}
}
License
This project is licensed under the Apache License 2.0. See the LICENSE file (or the header in the source files) for details.
